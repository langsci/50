\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

You are currently reading the book version of my doctoral dissertation which I successfully defended at the Vrije Universiteit Brussel on the 10\textsuperscript{th} of November 2000, slightly more than 13 years ago at the time of writing this preface. I feel privileged to have been the very first to implement Luc Steels' language game paradigm on a robotic platform. As you will read, the robots I used at that moment were very limited in their sensing, computational ressources and motor control. Moreover, I spent much time repairing the robots, as they were built from LEGO parts (not LEGO Mindstorms, which was not yet available at the start of my research) and a homemade sensorimotor board. As a result, the experimental setup and the evolved lexicons were also very limited. Nevertheless, the process of implementing the model, carrying out the experiments and analysing these, has provided a wealth of insights and knowledge on lexicon grounding in an evolutionary context, which, I believe, are still relevant today.

Much progress has been made since the writing of this dissertation. First, the language game paradigm has been implemented in more advanced robots, starting with the Talking Heads \citep{steelsetal:2002} and the Sony Aibo \citep{steelskaplan:2000}, which emerged while I was struggling with the LEGO robots, then soon followed by various humanoid platforms, such as Sony's Qrio \citep[see, e.g., ][ and this book series]{steels:2012}. Second, the cognitive architecture has become much more advanced through the development of FCG \citep{steelsdebeule:2006}, which allowed for more complex languages to emerge, resembling more closely natural languages. Third, the underlying processes of language games, in particular of the naming game, and the resulting dynamics in an evolutionary context have been widely studied using methods stemming from statistical mechanics \citep[e.g., ][]{baronchellietal:2006a}.

During the first years after the completion of my dissertation, I have published various studies from this book as journal articles \citep{vogt:2000c,vogt:2002a,vogt:2003a}. A broader review of using robots in studies of language evolution has appeared in \citet{vogt:2006a}. Building further on the work presented in this book, I formulated the {\em physical symbol grounding hypothesis} \citep{vogt:2002a}. This hypothesis essentially states that Harnad's (1990) symbol grounding problem is not a philosophical problem, but a technical problem that needs to be addressed by (virtual) robotic agents situated in a (virtual) environment, provided we adopt Peirce's semiotics, because according to this view, symbols have per definition meaning. As physical symbol grounding can in principle be achieved by individual agents, the ability to develop a shared symbolic communication system is a (much) harder challenge. This challenge, which I have called {\em social symbol grounding} \citep{vogtdivina:2007}, has remained my primary research focus.

The fact that I worked in a lab without robotic platforms, forced me to continue my research in simulations. Although simulations move away from the advantages of studying physically situated language development, it allowed me to scale up and, not unimportantly, speed up the research. 
Together with Hans Coumans, I reimplemented the three types of language games studied in this book (the observational game, the guessing game and what I then called the selfish game) in a simulation to demonstrate that the selfish game can work properly \citep{vogtcoumans:2003}, despite the results presented in this book. In my dissertation, the term 'selfish game' was used to indicate that the hearer had to interpret an utterance solely based on the utterance and the context without receiving additional cues through joint attention or feedback. I later discovered that the statistical learning method I implemented is known as {\em cross-situational learning} \citep{pinker:1989,siskind:1996}. As I have worked a lot on cross-situational learning (XSL) over the past decade, I have decided to change the term selfish game into {\em XSL game}. Apart from a few small typos, this is the only change made with respect to the original dissertation.

Over the years, I have become convinced that XSL is the basic learning mechanism that humans use to learn word-meaning mappings. XSL learning allows the learner to infer the meaning of a word by using the covariation of meanings that occur in the contexts of different situations. In \citet{smithetal:2006}, we have shown that XSL can be highly robust under large amounts of referential uncertainty (i.e. a lexicon can be learned well even when an agent hears a word in contexts containing many possible meanings). However, this was shown using a mathematical model containing many unrealistic assumptions. When relaxing such assumptions, such as using a robot (cf. this book), having many agents in the population \citep{vogtcoumans:2003} or assuming that words and meanings occur following a Zipfian distribution \citep{vogt:2012}, XSL is no longer that powerful. To resolve this, a learner requires additional cues, such as joint attention or corrective feedback, to learn a human-size lexicon. 

These ideas were further elaborated in the EU funded New Ties project \citep{gilbertetal:2006}, in which we aimed to set up a large scale ALife simulation, containing thousands of agents who â€˜lived' in a complex environment containing all sorts of objects, who could move around, and who would face all sorts of challenges in order to survive. The agents would learn to survive through evolutionary adaptation based on genetic transmission, individual learning and social learning of skills and language. Although we only succeeded partially, an interesting modification of the language game was implemented. In this implementation, agents could engage in a more dialogue-like interaction requesting additional cues or testing learnt vocabulary. They could also pass on learnt skills to other agents using the evolved language. The interactions could involve both joint attention and corrective feedback to reduce referential uncertainty, while learning was achieved through XSL \citep{vogtdivina:2007,vogthaasdijk:2010}.

Another line of research that I have carried out after writing this book, combined the language game paradigm with Kirby and Hurford's \citeyear{kirbyhurford:2002} {\em iterated learning model}, studying the emergence of compositional structures in language \citep{vogt:2005a,vogt:2005b}. This hybrid model, implemented in the simulation toolkit THSim \citep{vogt:2003c}, simulates the Talking Heads experiment.\footnote{Downloadable from http://ilk.uvt.nl/~{}pvogt/thsim.html.} These studies have provided fundamental insights on how compositionality might have evolved through cultural evolution by means of social interactions, social learning and self-organi-sation. Population dynamics, transmission over generations, and the active acquisition of language and meaning were considered crucial ingredients of this model (for an overview of the results, see \citet{vogt:2007b}).  

While I was making good progress with all this modelling work, providing interesting and testable predictions on language evolution and language acquisition, I increasingly realised the importance of validating these predictions with empirical data from studies with humans (or other animals). Together with Bart de Boer, we organised a week-long meeting in which language evolution modellers working on various topics were coupled to researchers working on empirical data from various fields, such as child language acquisition, animal communication, cognitive linguistics, etc. In this workshop, novel approaches to compare our models as closely as possible to empirical findings were developed \citep{vogtdeboer:2010}.

As there is virtually no empirical data on the evolution of word-meaning mappings, the most straightforward comparison that could be made with my modelling research was to compare to child language acquisition \citep{vogtlieven:2010}. Although there is a wealth of data on child language acquisition, none was found that captured the data needed to make a reliable comparison. Therefore, I decided to collect the data myself. This resulted in a project on which I have worked for over the past five years. Its aim is to develop longitudinal corpora of children's interactions with their (social) environment from different cultures (the Netherlands and Mozambique), together with parental estimates of the children's vocabulary size at different ages during children's second year of life. In these corpora, recordings of naturalistic observations are annotated based on the type of interactions (e.g. dyadic vs triadic interactions), the use of gestures such as pointing, the use of feedback, the child-directed speech and the children's social network of interactions. The resulting corpora  contain statistical descriptions of the types of interactions and stimuli which the children from the different cultures encounter. The idea is that these corpora can be used to set the parameters of language game simulations similar to the one described in \citet{vogthaasdijk:2010}. The aim is to simulate observed naturalistic interactions and to compare the lexicon development of the artificial agents with that of the simulated children. If the predictions from the simulations match the observed development of the children, then we may be confident that the model is an accurate (or at least highly plausible) theory of children's language acquisition. Development of the ultimate model, however, may take another 13 years. (For more details on this approach, consult \citeauthor{vogtmastin:2013}.)

 
Now, let us move on to where it all started for me. Before going there, however, I would like to apologise for any mistake that you may encounter, or visions I may no longer adhere to, and which could easily have been repaired if I would have had the time. Enjoy the rest of the journey.\\
\\
\noindent Paul Vogt\\
\noindent Tilburg, November 2013.
